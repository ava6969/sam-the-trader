runner:
  run: PPO
  checkpoint_freq: 20

  stop:
    timesteps_total: 1300000000
    training_iteration: 130000000
  config:
    env: BasicStockTrader-v0
    framework: torch
    num_workers: 8
    num_envs_per_worker: 8
    sgd_minibatch_size: 120
    vf_share_layers: True
    num_sgd_iter: 32
    num_gpus: 1
    rollout_fragment_length: 60 # trajectory = 1 hour of trade
    train_batch_size: 3840 # full day 60 * 8 * 8
#    vf_clip_param: 10000
    vf_loss_coeff: 0.01

    model:
      custom_model: sdae_full
      custom_model_config:
        train: True
      use_lstm: True
      fcnet_hiddens: [16, 32, 64, 128]
      fcnet_activation: relu
      lstm_cell_size: 128
      lstm_use_prev_action: True

    env_config:
      resolution: minute_1
      tickers: "RLOL-8"
      initial_amount: 25000
      tech_indicators: MACD!macd MA EMA ATR ROC
      log_every: 30000
      reward_type: PC
      max_shares: 3
      discrete_action: True
      bins: 7
      window: 1
      filter_date: False
      random_start: True
      episode_range: [500, 2000]
      test: False
      start_date: "2004-01-01 00:00:00"
      end_date: "2019-12-01 00:00:00"
